= AI For Customer Experiences: A Retail Example
include::_graphacademy_llm.adoc[]
:slug: graphrag-customer-experience
:author: Zach Blumenfeld
:category: genai-tutorials
:tags: 
:neo4j-versions: 5.x
:page-pagination:
:page-product: graphrag-customer-experience
//:imagesdir: https://dev.assets.neo4j.com/wp-content/uploads/2024/

//image::https://dist.neo4j.com/wp-content/uploads/20240618104511/build-kg-genai-e1718732751482.png[width=800, align=center,link="https://llm-graph-builder.neo4jlabs.com/",window="_blank"]

//TODO: Hero Image
GenAI + GraphRAG can help improve customer experiences throughout multiple touch-points in their journey, from

* discovery: generating personalized marketing and email content, to
* customized semantic search,
* targeted product recommendations, and
* compliant AI scripts for customer support,

This guide walks through setting up a full-stack GraphRAG application for all the above using Neo4j, LangChain (with LangServ), and OpenAI. The app focuses on a retail example using the https://github.com/neo4j-product-examples/graphrag-customer-experience#:~:text=H%26M%20Personalized%20Fashion%20Recommendations%20Dataset[H&M Personalized Fashion Recommendations Dataset^], a sample of real customer purchase data that includes rich information around products including names, types, descriptions, department sections, etc. All code presented in this tutorial is available in this https://github.com/neo4j-product-examples/graphrag-customer-experience[GitHub repository^].

//TODO: Architecture Diagram
== Running The App

=== Prerequisites

1. https://docs.docker.com/engine/install/[Docker^]
2. https://platform.openai.com/docs/quickstart/account-setup[OpenAI API Key^]

=== Setup
Clone the repository
[source, bash]
----
git clone https://github.com/neo4j-product-examples/graphrag-customer-experience.git
----

create  a `.env` file with the below. Fill in your OpenAI key. You can use our pre-loaded retail demo database to start.
The git repository has directions for creating the database from source data if you are interested.

[source, bash]
----
#Neo4j Database
NEO4J_URI=neo4j+s://demo.neo4jlabs.com
NEO4J_USERNAME=retail
NEO4J_PASSWORD=retail
NEO4J_DATABASE=retail

#OpenAI
OPENAI_API_KEY=sk-...

#Other
# used by UI to navigate between pages.
# Only change for
ADVERTISED_ADDRESS="http://localhost"
----

=== Run
To start the app, run the following command:
[source, bash]
----
docker-compose up
----

To start and rebuild (after changing env variables or code), run

[source, bash]
----
docker-compose up --build
----

To stop the app, run

[source, bash]
----
docker-compose down
----

Open `http://localhost:8501` in your browser to interact with the app.

== How Each Page Works

To understand how each page works it helps to first under the graph data models used.  For Discovery, Search, and Recommendations we use the below model.

//TODO: Schema vis
For support it resembles the below.
//TODO: Schema vis
=== Search
Once you understand how the search page works it will be easier to understand Discovery & Recommendation pages. For the search page the API will first create an embedding from the search term.  It will then take the resulting query vector and some other parameters and plug them into the following query to retrieve the search result. This query personalizes the results to each user based what similar users hav e been purchasing, using a logic similar to collaborative filtering.

[source, cypher]
----
//Match products based on the search query vector
CALL db.index.vector.queryNodes('product_text_embeddings', $vectorTopK, $embedding)
YIELD node, score
WITH node AS product, score AS searchScore

//calculate how often purchases of above products show up in local purchase graph "the purchaseScore" and re-rank
OPTIONAL MATCH(product)<-[:VARIANT_OF]-(:Article)<-[:PURCHASED]-(:Customer)
    -[:PURCHASED]->(a:Article)<-[:PURCHASED]-(:Customer {customerId: $customerId})
WITH count(a) AS purchaseScore, product, searchScore

//get corresponding articles, format results and return
OPTIONAL MATCH (product)<-[:VARIANT_OF]-(a:Article)
RETURN (1+purchaseScore)*searchScore AS score,
    collect({colourGroup: a.colourGroupName, graphicalAppearance: a.graphicalAppearanceName,
    articleId:a.articleId}) AS articleVariants,
    product {.*, `text`: Null, `textEmbedding`: Null, id: Null} AS metadata
    ORDER BY score DESC LIMIT $resTopK
----

This is a post-filtering using a graph pattern.

=== Discovery
The Discovery page uses the same retrieval query as above, but in an LLM chain, where the results are provided to an LLM to generate an email given context from other paramters like season/time-of-year.  Below is the LLM chain
[source, python]
----
content_chain = (
RunnableParallel(
{'context': (lambda x: (x['customer_interests'], x['customer_id'])) | RunnableLambda(retriever),
'customerName': (lambda x: x['customer_name']),
'customerInterests': (lambda x: x['customer_interests']),
'timeofYear': (lambda x: x['time_of_year']),
})
| prompt
| llm
| StrOutputParser()).with_types(input_type=ContentChainInput, output_type=ContentChainOutput)
----

In essence the search context and id for the user is passed to the retriever for the same graph query, while other details like customer name, interests, and time of year are passed to the LLM to help make decisions about choosing what content to write in the email.

The LLM prompt template is used:

[source, python]
----
f"""
You are a personal assistant named Sally for a fashion, home, and beauty company called HRM.
write an email to {customerName}, one of your customers, to recommend and summarize products based on:
- the current season / time of year: {timeofYear}
- Their recent searches & interests: {customerInterests}

Please only mention the products listed in the context below. Do not come up with or add any new products to the list.
The below candidates are recommended based on the purchase patterns of other customers in the HRM database.
Select the best 4 to 5 product subset from the context that best match
the time of year: {timeofYear} and the customers interests.
Each product comes with an https `url` field.
Make sure to provide that https url with descriptive name text in markdown for each product.

# Context:
"""
----

=== Recommendations
The Recommendations page uses a different type of retriever based on vector + graph embeddings.  The basic pattern is presented below.

//TODO: visual model of chain
We use Neo4j Graph Data Science (GDS) to create these embeddings. The embeddings create common co-purchase clusters as seen below
//TODO: TSNE plot snapshot (from notebook

The Retrieval Query looks like this
//TODO: Query template
And the LLM chain....
//TODO: code snippit
The LLM is given some creative authority to choose between mix and match items based on it's own language understanding of fasion and seasonality.
//TODO: prompt template code snippit
=== Customer Support
//TODO: this is just a simple chat interface that uses quantified path pattern to pull in facts/policies....KG builder based





